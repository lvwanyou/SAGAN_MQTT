\section{Experiment and Result Analysis}
In this section, MQTT and Modbus are chosen as our test targets from a variety of ICPs in the experiment. We generate a lot of test cases using the generative model. Then the generated data is used to stress test the target and trigger anomalies of the ICP. Finally,  according to the anomalies triggered, vulnerabilities in the anomalies are submitted for the improvement of the ICP after analysis to find the reason for the target anomalies. We evaluate the effectiveness of the proposed method by experimentation. 

\subsection{Environment construction of MQTT and Modbus}
To show the effectiveness and efficiency of our framework, we apply it to test MQTT, one of the mainstream ICPs. To indicate the versatility of our method, another ICP, Modbus, is also used to test.

\subsubsection{MQTT}
MQTT (Message Queuing Telemetry Transport) protocol is an application layer ICP based on publication and subscription under the ISO (International Organization for Standardization) standard and works on the TCP/IP protocol cluster. It is simple to implement, provides the transmission data with the quality of service, has the characteristics of lightweight, high bandwidth utilization efficiency, data independence and so on. The message format of MQTT is illustrated in Fig. \ref{FigMQTTFormat}.  

\begin{figure}[htbp]   %  插入一栏图片
	\centering 
	\includegraphics[width=3.5in]{FigMQTTFormat.pdf}
	\caption{Message format of MQTT}
	\label{FigMQTTFormat}
\end{figure}

In the experiment, we utilize Mosquitto v1.5.8 \cite{light2017mosquitto} as the open-source message broker of message push ICP MQTT v3.1 and  Paho-MQTT v1.0.2 \cite{light2017mosquitto} as the MQTT client. 

\subsubsection{Modbust-TCP}
There are many variants of Modbus, including Modbus-TCP, Modbus-UDP and so on. We choose Modbus-TCP as another fuzzing ICP in this study. It uses master-slave communication mode, in which the master communicates with the slave by sending and receiving data frames \cite{swales1999open}. 

\subsection{Evaluation Setup}
\subsubsection{Experimental Environment}
Tensorflow, one of the popular deep learning framework in the industrial community, is adopted to implement the model architecture. To improve the training efficiency, we train the model on a machine with 8 processors (Intel(R) Core (TM) i7-6700K CPU@4.00GHz)  16.0GB memory (RAM) Nvidia GeForce GTX 1080 Ti (11GB) and 64-bit ubuntu16.04, x64-based processor. When launching an attack, the simulators run on another machine with 4 processors (Intel (R) Core (TM) i5-5300U CPU@2.30GHz) 16.00GB memory (RAM) and 64-bit Microsoft Windows 10 Professional Operating System, x64-based processor.

\subsubsection{Model Training Setting}
As for the parameter setting, we initialize all weights from zero-centered Normal distribution with a standard deviation of 0.2, which can increase diversity to a certain extent. The mini-batch size is set to 32 in all models based on a large amount of training data. The $keep\_prob$ hyperparameter of dropout is set to 0.7. The learning rate of G and D is set to 0.0001 and 0.0004 in the Adam optimizer. As to the checkpoint in the generative model, the interval of model saving frequency is set to 10. We train the models for 100 epochs and save the generator model for every 10 epochs to get plentiful test cases.

\subsection{Fuzz Testing The Target ICP}
With the trained model, we generate test cases, input the system under test, and implement the fuzzy test process according to the standard fuzzy test process. In the process of inputting test cases into ICSs under test, we monitor the system in real time. If anomalies occur in the process, such as the output clobber problems and interface crash, we record and restart the test process at the current point. At the end of the entire test, we analyze the causes of antecedent anomalies and the logs of server systems to find the running status of potential vulnerabilities.

\begin{figure*}[htbp] 		 %  插入双栏图片
	\centering
	\includegraphics[width=5.5in]{FigModelW-distance.pdf}
	\caption{Dataset(500,000 test cases) W-distance over generator iterations (left) or wall-clock time (right) for SAGANFuzzer}
	\label{FigModelW-distance}
\end{figure*} 

\subsubsection{Training Data}
Training data in deep learning significantly influence model training. In the experiment, training data about the two industrial control protocols is collected separately. 

\begin{figure}[htbp]   %  插入一栏图片
	\centering 
	\includegraphics[width=3in]{FigMQTTEnvironment.pdf}
	\caption{MQTT enviroment}
	\label{FigMQTTEnvironment}
\end{figure}

\quad \textit{\textbf{a. MQTT.}}
In order to capture the MQTT communication data, an MQTT network environment based ICS is prepared as illustrated in Fig. \ref{FigMQTTEnvironment}. Wireshark \cite{orebaugh2006wireshark} is applied to grab packets during communication. These grabbed frames serve as the training data for the SAGANFuzzer framework. 
After fetching the connection information between the legal clients and the MQTT broker, we construct a disguised MQTT client to send the same connection information to connect to the broker in the IoT network with no authentication security measures. The disguised MQTT client launches the attack by sending fake MQTT messages which are generated by fuzzy test models. 

\quad \textit{\textbf{b. Modbus-TCP.}}
Pymodbus \cite{collins2013pymodbus}, a python package that implements the Modbus protocol, is used to generate the training data frames. Enough different types of data frames can be generated quickly via Pymodbus, which is practical and convenient. In the experiment, a Modbus-TCP implementation, Modbus RSSim v8.20, is applied as the fuzzing targets. The generated test cases are sent to the Modbus-TCP implementation by a python script over sockets to test the effects in simulated applications.


\subsubsection{Model Training}

One advantage of our method over weight clipping is largely overcoming the problem of unstable training of GANs, such as non-convergence, vanishing gradient and mode collapse. We design our model architecture based on these architectural constraints and improve training speed and sample quality. To demonstrate this, we train SAGANFuzzer with W-distance and gradient penalty on a dataset with 500,000 test cases and plot W-distance and losses of the generator and the discriminator of training in Figure \ref{FigModelW-distance}.



Following the setting in the subsection Model Training Setting, we train one model with the same optimizer (Adam) and learning rate as WGAN with weight clipping. The results also represent that our method converges faster and is more stable at convergence.

\subsubsection{Logging and Evaluation}
Logging is the basis for further analysis of model performance and fuzzing effectiveness. By analyzing logs of the communication process is an effective method to find ICPs’ anomalies. Some vulnerabilities may be manifested according to the obvious abnormal behavior of the system, and some behaviors need to be further analyzed. Based on the statistical analysis of the log file, we evaluate experimental results. Furthermore, we artificially analyze specific anomalies to get more details. Test data that causes target anomalies will be recollected and put into the training data set again. Data augmentation and value mutation operation will be applied to these data before putting it into the retraining data set. The retrained model with these mutated data can improve the capability of the model to detect vulnerabilities.

\subsection{Result Analysis}
In this part, we show the experimental results in three aspects. We first present some special anomalies that occurred in fuzzing the MQTT implementations. Then we reveal statistical results and their analysis. Lastly, to show the methodology’s protocol independence in ICP’s fuzz testing, the result of testing Modbus-TCP is presented.

\subsubsection{Statistical Analysis And Results}
The widely used General Purpose Fuzzer(GPF) \cite{demott2007revolutionizing}, CNN-1D model, LSTM-based seq2seq model, and WGAN-based model are chosen as fuzzers in the control group in this study. After fuzzers in the experimental group and control group are fully trained, fuzz testing is conducted by sending a total of 500,000 generated test cases to MQTT implementations through the TCP/1883 port.

According to the three aforementioned evaluation metrics, the effectiveness and efficiency of our fuzzing framework SAGANFuzzer and fuzzers in the control group are evaluated and represented graphically. Details are as follows.  

\begin{table*}[]
	\centering
	\caption{Performance Metrics Comparison}
	\label{F-measure}
	\renewcommand{\arraystretch}{1.35}
	\begin{tabular}{ m{70pt}<{\centering} |m{70pt}<{\centering}|m{40pt}<{\centering}|m{60pt}<{\centering}|m{40pt}<{\centering}|m{40pt}<{\centering}|m{40pt}<{\centering}}
		\toprule
		\textbf{Dataset
			(number of training cases)} & \textbf{Methods}          & \textbf{Year} & \textbf{F-measure} & \textbf{SE}     & \textbf{SP}     & \textbf{AC}     \\ \midrule
		& GPF              & 2007 & --         & 0.5252 & 0.5798 & 0.6474 \\ \cmidrule(l){2-7} 
		& CNN-1D model     & 2014 & 0.6701    & 0.8437 & 0.9743 & 0.8626 \\ \cmidrule(l){2-7} 
		10,000  & LSTM-based model & 2018 & 0.6300    & 0.8563 & 0.9007 & 0.8254 \\ \cmidrule(l){2-7} 
		& WGAN-based model & 2019 & 0.7960    & 0.7696 & 0.9115 & 0.8165 \\ \cmidrule(l){2-7} 
		& SAGANFuzzer      & 2020 & 0.8208    & 0.8274 & 0.9775 & 0.8608 \\ \midrule
		& GPF              & 2007 & --         & 0.5720 & 0.5730 & 0.6510 \\ \cmidrule(l){2-7} 
		& CNN-1D model     & 2014 & 0.8373    & 0.8670 & 0.9842 & 0.8690 \\ \cmidrule(l){2-7} 
		500,000 & LSTM-based model & 2018 & 0.8588    & 0.8203 & 0.9856 & 0.8700 \\ \cmidrule(l){2-7} 
		& WGAN-based model & 2019 & 0.8396    & 0.8108 & 0.9871 & 0.8906 \\ \cmidrule(l){2-7} 
		& SAGANFuzzer      & 2020 & 0.8502    & 0.8538 & 0.9878 & 0.9271 \\ \bottomrule
	\end{tabular}
\end{table*}

\quad \textit{\textbf{a. F-measure.}} Table \ref{F-measure} shows the accuracy of each method in generating legitimate test cases on a dataset of 10,000 and 500,000 training data. It can be observed from the table that the algorithm in this paper has Higher scores of Sensitivity, Accuracy, F-measure than CNN-1D model, LSTM-based seq2seq model and WGAN-based model in datasets of different sizes. Although the Sensitivity of the CNN-1D model and LSTM-based seq2seq model is higher than that of the method in this paper, the types of test cases generated are relatively single, and the algorithm in this paper has the highest F-measure. For the dataset of 10,000 training data, the F-measure of generating legitimate test cases reaches 82.08\%, which is 2.48\% higher than the WGAN-based model, and the Sensitivity of this method is 5.78\% higher than that of the WGAN-based model. On the dataset of 500,000 training data, our method is 1.06\% higher in F-measure and 4.30\% higher in Sensitivity than the WGAN-based model. 

Therefore, we can draw a conclusion from the evaluation metrics of the performance of machine learning models in the table: in terms of datasets with different data sizes, the model in this paper is superior to other fuzzy test case methods in each evaluation metric of generating legitimate test cases.


\quad \textit{\textbf{b. EVD.}}
In order to map the EVD values of each model to a relatively small scope for diagrammatic comparison, we normalize all EVD values under the same iteration through Z-score standardization. The experimental results of EVD are shown in Fig. \ref{FIGURE_EVD}. Due to not involving a continuously learning process, the performance of GPF has a downward trend on the targets when compared to the other four fuzzing models based on depth learning. From the perspective of the five models, the performance of the EVD indicators is: GPF $\textless$ CNN-1D model $\approx$ LSTM-based model $\textless$ GAN-based model $\textless$ SAGANFuzzer. 

\begin{figure}[htbp]
	\centering
	\includegraphics[width=3.36in]{FIGURE_EVD.jpg}
	\caption{EVD changes with the training epochs}
	\label{FIGURE_EVD}
\end{figure}
%generative adversarial
After training more than 30 epochs, the EVD rates of deep learning algorithms obviously exceed the GPF algorithm. With the rising trends of rates slow down significantly after 50 epochs, the average EVD rates of CNN-1D model and LSTM-based model are 60\% to 70\% compared with 75\% to 90\% of generative adversarial algorithms, which may be caused by the inability to learn a hierarchy of representations of the data effectively. Due to the unsupervised characteristic of generative adversarial algorithms, it may result in generating a large number of malformed protocol message sequences, leading to normal throwing which may cause EVD can not be further promoted. But for the generative adversarial algorithms from 50 to 100 epochs, the average EVD rate of SAGANFuzzer is approximately 8\% higher than the WGAN-based model, which indirectly indicates that SAGANFuzzer is more applicable to test cases generation for ICPs. It's worth going into detail that our trained model can effectively detect kinds of anomalies as presented in Table \ref{Triggered_Anomalies_SAGANFuzzer} with the gradient penalty, which shows we are likely to achieve the higher code coverage and the stronger ability of our model has to detect anomalies.
%Usually, the richer the data type, the higher code coverage we are likely to achieve, and the stronger ability a model has to detect anomalies.
\begin{table}[htbp]
	\caption{Triggered Anomalies and Triggered Frequency of SAGANFuzzer}
	\label{Triggered_Anomalies_SAGANFuzzer}
	\centering
	%
	\begin{tabular}{m{100pt}<{\centering}  m{40pt}<{\centering} m{50pt}<{\centering} }
		\toprule
		\bfseries Triggered Anomalies &  \bfseries Frequency (Times) & \bfseries ATITA (Mins)\\
		\midrule
		Using abnormal function code & 104 & 5.78\\
		Automatically closes window & 53 &10.64\\
		Data length unmatched & 121 & 4.52\\
		Abnormal address & 23 &13.26\\
		Integer overflow & 7 & 114.49 \\
		Broker memory overflow & 2 & 285.05 \\
		\bottomrule
	\end{tabular}
\end{table}

where Frequency represents the number at which the specified type of anomalies is triggered by the models during test time and average time interval of triggered anomalies (ATITA) is the quotient of the number of triggered anomalies and test time.

\quad \textit{\textbf{c. EFVD.}}
There is a huge difference in the training time of different GPF and the time of anomalies triggered by GPF is constant under different iterations, so it is not discussed in this part. The normalization of EVD is applied to EFVD, too. The testing depth has increased as illustrated in Fig. \ref{FIGURE_EVD} at the expense of reducing the code coverage of fuzz testing. But what makes a difference, rather, is that high test efficiency is maintained on the premise of attaining high EVD rates. The variation trend of EFVD of different deep learning based models is presented in Fig. \ref{FIGURE_EFVD}. It can be seen from the figure that when doing less training epochs, models with relatively short training time can achieve higher EFVD scores. And with the deepening of training, TAT values of different models become more and more different, so models with higher potential efficiency of vulnerability detection will get higher EFVD scores. Looking at the overall trend, the average EFVD score of our model is 19.45\% higher than that in the CNN-1D model, 15.14\% higher than the LSTM-based model and 5.26\% higher than the WGAN-based model. And the fluctuation of our model is relatively small, which indicates that our model can maintain relatively stable efficiency on the basis of balancing TT and TAT.

%When the training epochs is 10, the TT of the four deep learning based models maintains the best. After training, some message categories are generally lost, as presented in Fig. \ref{FIGURE_EFVD}.。

%A total of 13 categories of Modbus data frames are prepared in the raw data. 

%When the training epochs is 10, the diversity of the three deep learning based models maintains the best. 

%After training, some message categories are generally lost.

%BLSTM-DCNNFuzz and LSTM-based model have a good performance on maintaining basically the test case diversity, which illustrates the two models can learn the time-step dimension of protocol messages. And owing to the BLSTM model containing two sub-networks for the forward and backward sequence context respectively, it is able for the BLSTM-DCNNFuzz to exploit information from both the past and the future, which performs better than LSTM-based model. 

\begin{figure}[htbp]
	\centering
	\includegraphics[width=3.3in]{FIGURE_EFVD.jpg}
	\caption{EFVD changes with the training epochs}
	\label{FIGURE_EFVD}
\end{figure}

%\subsubsection{Potential Vulnerabilities Found}

\subsubsection{Applying The Method to Modbus-TCP}
As shown in Table \ref{table_MQTT}, we detect these potential vulnerabilities, including slave crash, station off-line, working counter attack, using abnormal function code and so on, in Modbus-TCP via the new trained SAGANFuzzer. In the experiment, we send the generated data messages $S_i$ to the slave stations and record the corresponding received message $R_i$. Massive message pairs $<S_i, R_i>$ are obtained. According to the abnormal protocol characterization above, we analyze and compare the specified field values and obtained the following statistical results. Experiments on the Modbus-TCP protocol prove that our method has great versatility.% {350pt}{lcc}

\begin{table}[htbp]
	\caption{Potential Vulnerabilities and  in Modbus-TCP}
	\label{table_MQTT}
	\centering
	\begin{tabular} {p{100pt}<{\centering} p{40pt}<{\centering} p{50pt}<{\centering}}
		\toprule
		\makecell[tl]{\bfseries Triggered Anomalies} &  {\bfseries NTA} & {\bfseries ATITA (Mins)} \\
		\midrule
		\makecell[tl]{Slave crash}  & {29 times} & 21.11 \\
		\makecell[tl]{Station ID xx off-line} & {164 times} & 0.79 \\
		\makecell[tl]{Working counter attack}   & {14 times } &  28.13\\
		\makecell[tl]{Using abnormal function code}  & {207 times} & 0.52 \\
		\makecell[tl]{Automatically closes window}  & {13 times} & 28.47 \\
		\makecell[tl]{Data length unmatched}  & {190 times} & 0.63\\
		\makecell[tl]{Debugger memory overflow}  & {4 times} & 41.85 \\
		\makecell[tl]{Unknown attack}  & {197 times} & 0.59 \\
		\bottomrule
	\end{tabular}
\end{table}
where number of Triggered anomalies(NTA) represents the total number of anomalies triggered by the models during test time.

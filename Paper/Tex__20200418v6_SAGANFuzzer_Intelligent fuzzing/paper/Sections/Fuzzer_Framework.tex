\section{SAGANFuzzer Framework}
In this section, we first acquire a large number of communication data from the ICS to be tested and then preprocess the data as the training data of the deep adversarial learning model established. Secondly, a generative model and a discriminant model are designed to generate the adversarial network, and a specific model is obtained by training and retraining the model with the acquired data. Finally, a series of performance metrics are put forward to evaluate our model.


\subsection{Preprocessing of ICP Message Frames}
In order to get diverse test cases, reach high code coverage and desirable fuzzing results, data preprocessing is a necessary part. There are two steps in preprocessing: \textbf{Message Frame Clustering} and \textbf{Data Conversion}.

\subsubsection{\textbf{Message Frame Clustering}}
After message frames collection, there are many different length message frames of MQTT. We adopted the Length Clustering method to preprocess the data frames. It is noted that most message frames with the same length share the same frame type. First, we gather the data frames which have the same length. In order not to get too many groups of data frames, groups whose quantity is less than a threshold (e.g. 5000) will be moved from the longer adjacent group, while group contains more data than the threshold are left unchanged. In such a way, there may be message frames with different lengths in one group. After clustering, we select the max length of message frames for every group and add special token `u' at the end of message frames whose length is less than max length.

\subsubsection{\textbf{Data Conversion}}
Raw data frames of most protocols are hexadecimal, which can not be fed into the model directly. So after clustering, we will map the hexadecimal data frames into the digital vectors. The vocabulary we use is as followed:
\begin{equation}
\textit{\textbf{0 1 2 3 4 5 6 7 8 9 a b c d e f u}}
\end{equation}
The size of the vocabulary is 17, there are ten digits and seven characters according to the hexadecimal message frames and the supplement token `u'.
Based on the vocabulary, we convert our message frames $x \in R^{seq\_size \times 1}$ into one hot vector $X \in R^{seq\_size \times 17}$(seq\_size is the max length of the current group). And one-hot vectors will be the input of the discriminator which will be discussed in \textcolor[rgb]{1,0,0}{4.2}.

\begin{figure}[htbp]   %  插入一栏图片
	\centering 
	\includegraphics[width=3.5in]{FigSAGANFuzzer_model.pdf}
	\caption{The architecture of SAGANFuzzer}
	\label{FigSAGANFuzzer_model}
\end{figure}
\subsection{Model Design} 
\label{sec:model_design} 
In this part, we describe our test case generation model in detail. As Fig. \ref{FigSAGANFuzzer_model} shows, our model consists of a generator and a critic, which is the same as a WGAN model. The generator is born to generate the fake message frames and the critic will evaluate the Wasserstein distance. The Wasserstein distance is the minimum cost of transporting mass in converting the data distribution $q$ to the data distribution $p$. During the training, the Wasserstein distance between real message frame distribution and our fake message frame distribution will be shortened and our model grasps the knowledge of the protocol grammar.

% 这里可以提一些WGANGP的优点，为什么要选WGANGP，记得去调研其他基于WGANGP的论文怎么写的

\begin{figure}[htbp]   %  插入一栏图片
	\centering 
	\includegraphics[width=3.5in]{FigSAGANFuzzer_Generator.pdf}
	\caption{Generator Network}
	\label{FigSAGANFuzzer_Generator}
\end{figure}
\subsubsection{\textbf{Generator}}

%总体描述，分为四个部分，四个部分里面分别是什么，简单介绍作用
The structure of the generator is as followed in Fig. \ref{FigSAGANFuzzer_Generator}. There are four parts, noise block, conversion block, transformer block, and output block. In order to generate different message frame data every time, the noise block will output some random noise data $z \in \mathbb{R}^{1 \times zd}$ where $zd$ is a hyperparameter. And it is a common practice to set the noise data to Gaussian distributed noise. 

The conversion block contains a fully connected layer and a reshape layer. This block will convert the noise data $z$ into Noise Conversion Representation (NCR) $\tilde{z} \in \mathbb{R}^{ss \times dm}$ where $ss$ is the max sequence length of the current group and $dm$ is the number of feature dimension.

The transformer block contains a positional encoding layer and an encoder sub-block. The encoder sub-block is the same as the encoder part of the Transformer \cite{vaswani2017attention}. It is formed by a multi-head self-attention layer and a feed-forward layer. Besides, there is a residual connection around each of the two layers, followed by layer normalization. And the input and output of the transformer are the same, so we can repeat this part as many times as we want.

The output block is a fully connected layer and a softmax layer. After the conversion block and the transformer block, the generator will not output the message frame data directly, instead, it outputs a probability vectors $\tilde{x} \in \mathbb{R}^{ss \times vs}$. Where $vs$ is the size of vocabulary, which is $17$ in our situation. If we want to check the quality of message frames generated by the generator, we can apply $argmax$ function on $\tilde{x}$ out of the model and then translate to hexadecimal data.

The sequence information is normally one-dimensional vector, but during the computation in the NLP model, the sequence information is represented by two-dimensional vectors including word embedding or one-hot vector for the sake of a better representation of the sequence. 
For example, the input words of the Transformer are converted into word embedding. In our model, we feed NCR to our transformer block. Why don't we use word embedding? There is a problem that the output of the noise block is a random noise vector, it is hard to get the corresponding word embedding. In the NLP tasks, discrete data is usually regarded as the result of continuous sampling from the categorical distribution. If we force to find the word embedding with some tricks, it may cause the whole procedure non-derivable, which will make the backpropagation algorithm unavailable. 
The solution of most GAN text generation model is using the one-hot vector to replace the word embedding in the model. In this paper, our solution is NCR. Define the fully connected layer as $f$, processed by fully connected layer, ReLU activation and reshape operation, noise data $z$ will become $\tilde{z} = Reshape(f(z))$ and $ \tilde{z} \in \mathbb{R}^{ss \times {dm}}$. And it is the input of the transformer block.
NCR looks like word embedding, but it is fake. NCR maps the one-dimension noise vector to high dimensional space information. Comparing with the one-hot vector, NCR can cover more information of high dimension space because most digits of one-hot vectors are zero.
The transformer block is a feature extractor. Compared with the commonly used feature extractor, Recurrent Neural Network (RNN), the transformer block is better in semantic feature extraction and long-range feature extraction. What's more, the self-attention layer in the transformer block supports parallel training, which can accelerate the training process.
The loss function of the generator is 
\begin{equation}
L_{g} = - \mathop{\mathbb{E}}\limits_{\tilde{x}\sim\mathbb{P}_{g}}\left [ D(\tilde{x}) \right ] 
\end{equation}
where $\tilde{x} \in \mathbb{R}^{ss \times vs}$ is the output of the generator, $\mathbb{P}_g$ is the model distribution implicitly defined by $\tilde{x}=G(z)$, and $z$ is the noise data.

\begin{figure}[htbp]   %  插入一栏图片
	\centering 
	\includegraphics[width=1.5in]{FigSAGANFuzzer_Critic.pdf}
	\caption{Generator Network}
	\label{FigSAGANFuzzer_Critic}
\end{figure}
\subsubsection{\textbf{Critic}}
It looks like discriminator in normal GAN model, but it is not a classifier, we call it critic here, which is the same as WGAN \cite{arjovsky2017wasserstein}. The structure of the critic is as Fig. \ref{FigSAGANFuzzer_Critic} shows. The critic includes five conv1d layers, five self-attention layers, and one fully connected layer. For the critic, there are two types of inputs. One is the one-hot vector from the real message frames, and another is the output of the generator which represents the fake message frames. 
The second dimension of the output of the generator means the probability of each word in the vocabulary, and one-hot vector can also be understood as a special case of it, that is, the probability of one word is 1 and the probability of other words is 0. From the table, we can see that the first conv1d layer changes the second dimension of inputs from the probability of word to the feature representation, which is the same as the dimension of NCR.
It is noted that every conv1d layer followed by a self-attention layer. It is a little different that the filter size of conv1d is not the same. The filter size of conv1d $fs$ are $(dm, w)$ where $ds$ is the number of features and $w \in {1,2,3,4,5}$. It is well known that protocols have message headers, which specify the content of the message body in the message frame. More simply, the front part of message frames affects the back part of the message frame. 

If we don't know the grammar of the protocol, it is hard to distinguish the boundary of two parts. If the model has learned which part is the message header, it can pay more attention to the message header part.
Here we use a conv1d layer to figure out. Due to different protocols have different length of the message header, we change the filter size of conv1d to capture this information better.
As for the content in the message header, several flags affect several parts of the content in the message body. As \textcolor[rgb]{1,0,0}{Fig. 4} illustrated, message headers are divided into three parts and each part will affect the corresponding part in the message body. In order to capture how the content in the message header affects specific parts of the message body, we use self-attention layers. 
Self-attention considers the attention weight of every position of the input and is good at learning long-range dependencies. With the boundary information leaned by conv1d layers, self-attention layers will pay more attention to the correlation between the content in the message header and body.
After repeated self-attention and conv1d layers five times, there is a reshape layer and a fully connected layer. Finally, the critic will output a scalar score. 
The critic loss is:
\begin{equation}
L_{c} = \mathop{\mathbb{E}}\limits_{\tilde{x}\sim\mathbb{P}_{g}}\left [ D(\tilde{x}) \right ] 
- \mathop{\mathbb{E}}\limits_{x\sim\mathbb{P}_{r}}\left [ D(x) \right ] 
+ \lambda\mathop{\mathbb{E}}\limits_{\hat{x}\sim\mathbb{P}_{\hat{x}}}\left [ ( \left \| \triangledown_{\hat{x}}D( \hat{x}) \right \|_{2} - 1 )^{2} \right ]
\end{equation}

where $\mathbb{P}_{\tilde{x}}$ define sampling uniformly along straight lines between pairs of points sampled from the real data distribution $\mathbb{P}_{r}$ and the generator distribution $\mathbb{P}_{g}$. 
In order to satisfy the 1-Lipschitz constraint, we adopted the solution of WGAN-GP. We use gradient penalty instead of the weight clipping to enforce the 1-Lipschitz constraint. It makes training more stable and therefore easier to train.

\subsubsection{\textbf{Training strategy}}
Once the model design is completed, we begin to train our model. Under normal circumstances, the training of the GAN is adversarial, which means the generator and discriminator (critic) should be on the same level. If the imbalance is too serious, another one will learn nothing. And this is the reason why the GAN model is difficult to train and the training is unstable.
Due to the properties of the Wasserstein distance, we can train the critic better first and then narrow the Wasserstein distance between fake message frame distribution and real message frame distribution, which is the process of improving generator. In every epoch, we train generator once and then train the critic $c\_iters$ ($5$ in our model) times. We use Adam Optimizer with the learning rate of $0.0004$, beta1 $0.5$ and beta2 $0.9$ in the generator and the critic. In order to judge the convergence of the model, we use the following equation, which is the approximate value of the Wasserstein distance.
\begin{equation}
wd = 
\mathop{\mathbb{E}}\limits_{x\sim\mathbb{P}_{r}}\left [ D(x) \right ] 
- \mathop{\mathbb{E}}\limits_{\tilde{x}\sim\mathbb{P}_{g}}\left [ D(\tilde{x}) \right ] 
\end{equation}
Even we want to generate the fake message frames that share high similarity to the real message frames, the ulmate goal of our model is to achieve effective fuzzing results and identify as many bugs as possible. In order to obtain the desired results, we need some differences between the real data and the fake data. So we not only save the final version of the model, which is converged, but also the intermediate generator model. We save the generator model every 10 training epoch deliberately. In such a training strategy, we can achieve the goal of the high code coverage and deeper testing depth.

\subsection{Performance Metrics}
Some quantitative criteria \cite{heusel2017gans} \cite{karras2017progressive} \cite{lucic2018gans} have emerged only recently assessing GAN on image generation. However, there is no corresponding evaluation metrics in fuzzing based on deep adversarial learning, and the lack of these indicators includes two aspects:  
 \cite{karras2017progressive} \cite{lucic2018gans} in the field of fuzzing based on deep learning \cite{shmelkov2018good} and the evaluation of the vulnerability detection capability. Therefore, in accordance with our research purpose and specific situation, the following evaluation metrics are proposed in this study.

\subsubsection{\textbf{F-measure}}
In order to further demonstrate the performance of our model in this paper, we compare the performance of different models on test data generation of ICPs with several indexs such as \textit{Sensitivity}, \textit{Specificity}, \textit{Accuracy} and \textit{F-measure} in the same data set.  Among them, Sensitivity represents the percentage of function codes for correctly generated test case packages versus function codes for real test case packages, Specificity means to the percentage of non-essential characters for correctly generated test case packages versus non-essential characters for real test case packages, and Accuracy is the percentage of the entire test case that correctly generates the format and message content of the test case package. The specific formula is as follows:
\begin{equation}
Accuracy = \frac{{TP + TN}}{{TP + FN + TN + FP}}
\end{equation}
\begin{equation}
Sensitivity = \frac{{TP}}{{TP + FN}}
\end{equation}
\begin{equation}
Specificity = \frac{{TN}}{{TN + FP}}
\end{equation}
\begin{equation}
Precision = \frac{{TP}}{{TP + FP}}
\end{equation}
\begin{equation}
Recall = \frac{{TP}}{{TP + FN}}
\end{equation}
\begin{equation}
\begin{array}{l}
F - measure = 2 \times precision \times \\
{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} \frac{{Recall}}{{Precision + Recall}}
\end{array}
\end{equation}
wherein, TP is the number of correctly generated characters that constitute the function codes of ICPs' packages, TN is the number of correctly generated other non-essential characters including message content of ICPs' packages, FP is the number of characters  generated by error that constitute the function codes of ICPs' packages, and FN is the number of generated by error other non-essential characters including message content of ICPs' packages.

\subsubsection{\textbf{Effectiveness of Vulnerability Detection (EVD)}}
EVD refers to the ability to trigger anomalies of the test target based on the test target accepting the test data. The effectiveness evaluation of the fuzzing methods can be divided into two aspects: testing depth and code coverage. The effectiveness of fuzz testing depends predominantly on the testing depth and high code coverage. Therefore, we propose the effectiveness evaluation metric EVD of the model from the above two aspects.

When the generated data can be accepted by the test target, it indicates that the generated data is similar to real data in terms of format, embodying that the model has the ability to learn the format of data from the real world. And this phenomenon also reflects a certain depth of testing. Our ultimate goal is to trigger as many anomalies as possible to the ICS to find vulnerabilities, so we need to take two sub-metrics into account when we finally calculate the testing depth for EVD: \textit{Acceptance Rate of Test Cases (ARTC)} and \textit{Ability of Vulnerability Detected (AVD)}:

\quad \textit{\textbf{a. ARTC.}} ARTC refers to the acceptance rate at which the generated test data is received by the test target when it is sent to the test target. The specific formula is as follows:
\begin{equation}
ARTC = \frac{{N_{accepted}}}{{N_{all}}} \times 100\%  
\end{equation}
where ${N_{accepted}}$ is the total number of test cases recognized and ${N_{all}}$ is the total number of test cases sent.

\quad \textit{\textbf{b. AVD.}} AVD refers to the ability to trigger anomalies of the test target when the generated test data is sent to the test target. We define AVD as follows:
\begin{equation}
AVD = \frac{{N_{anomalies}}}{{N_{all}}} \times 100\%  
\end{equation}
where ${N_{anomalies}}$ is the total number of test cases which trigger anomalies and ${N_{all}}$ is the total number of test cases sent.

\textit{\textbf{Diversity of Generated Cases (DGC)}} is a sub-metric proposed as the extent of code coverage of fuzz testing in EVD. It refers to the ability to maintain the diversity of the training data. Furthermore, The diversity-based approach is a useful test case selection criterion for code coverage \cite{hemmati2013achieving} \cite{mondal2015exploring} . More diverse generated test data frames are likely to cause more exceptions. And this indicator focuses on the number of message types in the generated data, see the following formula: 
\begin{equation}
DGC = \frac{{N_{gen\_categories}}}{{N_{all\_categories}}} \times 100\% 
\end{equation}
where $N_{gen\_categories}$ is the total number of message categories in the generated data frames, and $N_{all\_categories}$ is the total number of message categories in the training set.

In order to balance the different weights of sub-metrics on model effectiveness, dimensionless quantity method is applied to eliminate the influence of different scales between sub-metrics so that each sub-metric is converted into a value that can be directly added or subtracted. We normalize the submetrics and add them up to get the comprehensive scores for EVD:
\begin{equation}
\begin{array}{l}
EVD=(\displaystyle\frac{{ART{C_i} - ART{C_{\min }}}}{{ART{C_{\max }} - ART{C_{\min }}}} + \frac{{VD{E_i} - VD{E_{\min }}}}{{VD{E_{\max }} - VD{{E}_{\min }}}}\\
\\{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  {\kern 1pt} {\kern 1pt} {\kern 1pt}  
+ {\kern 1pt} \displaystyle\frac{{DG{C_i} - DG{C_{\min }}}}{{DG{C_{\max }} - DG{C_{\min }}}}) \times \displaystyle\frac{{100}}{3}{\kern 1pt}
\end{array}
\end{equation}

setting the values of different effectiveness sub-metrics of a model as \{${{submetric}_1}$, ${submetric_2}$, ... , ${submetric_n}$\}, then values of ARTC, AVD and DGC of the ith model are: ${ARTC_i}$, ${AVD_i}$ and ${DGC_i}$. ${{submetric}_{max}}$ and ${{submetric}_{min}}$ are respectively the maximum and minimum values of the corresponding sub-metric.

\subsubsection{\textbf{Efficiency of Vulnerability Detection (EFVD)}}
EFVD is an important indicator of model Efficiency. On one hand, EFVD refers to the \textit{Training Time (TT)} it takes to train a model. On the other hand, it reflects the \textit{Time of Anomalies Triggered (TAT)} after sending a fixed number of test cases. 

\quad \textit{\textbf{a. TT.}} Short TT correspondingly improves the efficiency of testing.

\quad \textit{\textbf{b. TAT.}} TAT refers to the time interval from the first request (${t_1}$) to the third check out of the anomalies (such as error code 3, no response from the server, etc.) for each fuzzy test as a formula for TAT in this paper:
\begin{equation}
TAT={t_{{3_{{\rm{th}}}}\_{\rm{anomaly}}}} - {t_1}  
\end{equation}
It should be noted that the number of anomalies found is also related to the test target. Weak target will highlight the method effectiveness. However, in this study, we only focus on the efficiency of the method. The specific formula is as follows:

\begin{equation}
\begin{array}{l}
EFVD=(\displaystyle\frac{{T{T_i} - T{T_{\min }}}}{{T{T_{\max }} - T{T_{\min }}}} + \frac{{TA{T_i} - TA{T_{\min }}}}{{TA{T_{\max }} - TA{T_{\min }}}})\\
\\{\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt} {\kern 1pt}  {\kern 1pt} {\kern 1pt} {\kern 1pt}  
\times \displaystyle\frac{{100}}{2}{\kern 1pt}
\end{array}
\end{equation}

similar to aforementioned effectiveness sub-metrics, the values of TT and TAT of the ith model are: ${TT_i}$ and ${TAT_i}$. ${{TT}_{max}}$ and ${{TAT}_{min}}$ are respectively the maximum and minimum values of the corresponding sub-metric.

